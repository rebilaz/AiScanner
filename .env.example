# Google Cloud configuration
GCP_PROJECT_ID=your-project-id
BQ_DATASET=your_dataset
BQ_TABLE=market_table
GOOGLE_APPLICATION_CREDENTIALS=/path/to/credentials.json
HTTPS_PROXY=http://proxy:8080
SSL_CERT_FILE=/path/to/cert.crt

# Optional Playwright remote browser websocket
PLAYWRIGHT_WS=

# Enable or disable specific exchange clients (comma-separated list)
ENABLED_CLIENTS=Binance,Kraken

# Rate limits (requests per second)
BINANCE_RATE_LIMIT=5
KRAKEN_RATE_LIMIT=5

# Trading configuration
TRADING_PAIRS=BTC/USDT,ETH/USDT 
INTERVAL=1m

THEGRAPH_UNISWAP_ENDPOINT=https://api.thegraph.com/subgraphs/name/uniswap/uniswap-v3
DEX_BIGQUERY_TABLE=dex_market_data

# workers/worker_2_1.py : Collecte les informations fondamentales des tokens depuis CoinGecko
COINGECKO_API_KEY=
COINGECKO_CATEGORY=artificial-intelligence
COINGECKO_MIN_MARKET_CAP=10000000
COINGECKO_MIN_VOLUME_USD=50000
COINGECKO_BATCH_SIZE=20
COINGECKO_BIGQUERY_TABLE=Market_data

# workers/worker_2_2.py : Analyse l'activité des dépôts GitHub liés aux projets et produit divers scores
PAT_GITHUB=
GITHUB_SOURCE_TABLE=Market_data
GITHUB_DEST_TABLE=github_score
GITHUB_BATCH_SIZE=20

# workers/worker_2_3.py : Calcule des métriques on-chain (TVL, activité des baleines…) à partir des API scan
ETHERSCAN_API_KEY=
BSCSCAN_API_KEY=
POLYGONSCAN_API_KEY=
ONCHAIN_BIGQUERY_TABLE=onchain_metrics
BQ_STATIC_TABLE=Market_data
BQ_MARKET_TABLE=Market_data
ONCHAIN_BATCH_SIZE=20
WHALE_TRANSACTION_USD=100000

# ---------------------------------------------------------------------------
# workers/worker_6_3.py : Produit un score global de classement des actifs \
# à partir de métriques normalisées
# ---------------------------------------------------------------------------
BQ_PRICE_FEATURES_TABLE=asset_price_features
BQ_PREDICTIONS_TABLE=asset_trend_predictions
PRICE_MODEL_PATH=trend_model/model.pkl
PREDICTION_WINDOW_DAYS=30

# ---------------------------------------------------------------------------
# workers/worker_7_1.py : Collecte les messages sociaux (Twitter, Reddit…)
# ---------------------------------------------------------------------------
SOCIAL_CONFIG_FILE=social/config.yaml
BQ_SOCIAL_TABLE=raw_social_posts
TWITTER_BEARER_TOKEN=
TWITTER_MAX_RESULTS=50
REDDIT_CLIENT_ID=
REDDIT_CLIENT_SECRET=
REDDIT_USER_AGENT=social-scraper
REDDIT_MAX_RESULTS=50

# ---------------------------------------------------------------------------
# workers/worker_7_2.py : Génère des sujets récurrents dans les articles grâce au modèle BERTopic
# ---------------------------------------------------------------------------
NEWS_CONFIG_FILE=news/config.yaml
BQ_ARTICLES_TABLE=raw_articles

# ---------------------------------------------------------------------------
# Alert engine configuration
# ---------------------------------------------------------------------------
ALERT_CONFIG_FILE=alerts/alert_rules.yaml
SLACK_WEBHOOK_URL=
BQ_SENTIMENT_TABLE=social_sentiment_timeseries
BQ_GITHUB_TABLE=github_score
BQ_LABELED_ADDRESSES_TABLE=labeled_addresses

# ---------------------------------------------------------------------------
# Community listener configuration
# ---------------------------------------------------------------------------
COMMUNITY_CONFIG_FILE=community/config.yaml
BQ_COMMUNITY_TABLE=raw_community_messages
DISCORD_BOT_TOKEN=
TELEGRAM_API_ID=
TELEGRAM_API_HASH=
TELEGRAM_BOT_TOKEN=

# ---------------------------------------------------------------------------
# workers/worker_7_4.py : Suit l'évolution des collections NFT et déclenche des analyses de sécurité
# ---------------------------------------------------------------------------
BQ_TOKEN_TRANSFERS_TABLE=token_transfers
BQ_NFT_TRENDS_TABLE=nft_collection_trends
BQ_SECURITY_TASKS_TABLE=security_analysis_tasks
NFT_CONFIG_PATH=nft/config.yaml
OPENSEA_API_KEY=
BQ_NFT_RARITY_TABLE=nft_rarity_scores

# ---------------------------------------------------------------------------
# workers/worker_7_3.py : Crée des résumés prudents d'articles via un LLM et les stocke pour validation humaine
# ---------------------------------------------------------------------------
BQ_SUMMARY_TABLE=article_summaries
SUMMARY_MODEL=gpt-4-turbo
SUMMARY_BATCH_SIZE=10
OPENAI_API_KEY=

# ---------------------------------------------------------------------------
# workers/worker_4_1.py, worker_4_2.py et worker_4_3.py : analyse sécuritaire des contrats (téléchargement, Slither, modèle ML)
# ---------------------------------------------------------------------------
BQ_CONTRACTS_TABLE=contracts
BQ_CONTRACT_CODE_TABLE=contract_code
BQ_STATIC_ANALYSIS_TABLE=contract_static_analysis
BQ_ML_ANALYSIS_TABLE=contract_ml_analysis
CONTRACT_BATCH_SIZE=100
EXPLORER_RATE_LIMIT=5
STATIC_ANALYSIS_BATCH_SIZE=20
ML_ANALYSIS_BATCH_SIZE=20
OPCODE_VECTORIZER=vectorizer.joblib
OPCODE_MODEL=model.joblib

# ---------------------------------------------------------------------------
# workers/worker_5_1.py : Agrège les flux de liquidité des bridges entre chaînes
# ---------------------------------------------------------------------------
BQ_DAILY_FLOWS_TABLE=daily_cross_chain_flows
BRIDGES_CONFIG_PATH=bridges/bridges_config.yaml
LOOKBACK_DAYS=1

# ---------------------------------------------------------------------------
# workers/worker_5_2.py : Évalue la TVL et les revenus des protocoles DeFi et les compare aux chiffres de DeFiLlama
# ---------------------------------------------------------------------------
BQ_PROTOCOL_METRICS_TABLE=protocol_metrics

# ---------------------------------------------------------------------------
# workers/worker_eth_sync.py : Synchronise les tables publiques Ethereum de Google Cloud vers BigQuery
# ---------------------------------------------------------------------------
ETH_SYNC_MAX_BLOCKS=0
BQ_TRANSACTIONS_TABLE=eth_transactions
BQ_LOGS_TABLE=eth_logs
BQ_TOKEN_TRANSFERS_TABLE=eth_token_transfers
BQ_TRACES_TABLE=eth_traces

# ---------------------------------------------------------------------------
# workers/worker_3_1.py : Décode les logs Ethereum en événements nommés à l'aide des ABI
# ---------------------------------------------------------------------------
BQ_LOGS_RAW_TABLE=logs_raw
BQ_TOKENS_TABLE=token_addresses
BQ_LABELED_EVENTS_TABLE=labeled_events
EVENTS_BATCH_SIZE=1000

# ---------------------------------------------------------------------------
# workers/worker_3_2.py : Identifie les "whales" et les adresses "smart money" via les transferts de tokens
# ---------------------------------------------------------------------------
BQ_PRICES_TABLE=token_prices
SMART_MONEY_SCORE_THRESHOLD=3
BQ_LABELED_ADDRESSES_TABLE=labeled_addresses

# ---------------------------------------------------------------------------
# workers/worker_7_2.py : Génère des sujets récurrents dans les articles grâce au modèle BERTopic et suit leur prévalence
# ---------------------------------------------------------------------------
BQ_TOPIC_TABLE=topic_definitions
BQ_NARRATIVE_TABLE=narrative_prevalence_timeseries
TOPIC_LOOKBACK_DAYS=90
TOPIC_MIN_SIZE=10
TOPIC_EMBED_MODEL=all-MiniLM-L6-v2

# ---------------------------------------------------------------------------
# workers/worker_7_1.py : Mesure le sentiment social en analysant les messages publics et communautaires
# ---------------------------------------------------------------------------
ASSET_MAPPING_FILE=assets.yaml
SENTIMENT_MODEL=ProsusAI/finbert
SENTIMENT_BATCH_SIZE=32
