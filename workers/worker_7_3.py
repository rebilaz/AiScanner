"""Generate cautious LLM summaries of articles and store them in BigQuery.

WARNING: Summaries produced by this script are generated by a large language
model and may contain errors or biased interpretations. Every summary MUST be
reviewed by a human before any downstream use. The `is_human_validated` column
in the `article_summaries` table tracks this requirement. Summaries should never
be consumed automatically for scoring, alerting or decision making without
explicit human validation and a link to the original article.
"""

from __future__ import annotations

import logging
import os
from datetime import datetime, timezone
from typing import List

import pandas as pd
from google.cloud import bigquery
from gcp_utils import create_bq_client
import openai

logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")

# ---------------------------------------------------------------------------
# Configuration
# ---------------------------------------------------------------------------
PROJECT_ID = os.getenv("GCP_PROJECT_ID")
DATASET = os.getenv("BQ_DATASET")
ARTICLE_TABLE = os.getenv("BQ_ARTICLES_TABLE", "raw_articles")
SUMMARY_TABLE = os.getenv("BQ_SUMMARY_TABLE", "article_summaries")
MODEL_NAME = os.getenv("SUMMARY_MODEL", "gpt-4-turbo")
BATCH_SIZE = int(os.getenv("SUMMARY_BATCH_SIZE", "10"))
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

SYSTEM_PROMPT = (
    "Tu es un analyste de recherche méticuleux et prudent. Ta tâche est de "
    "résumer le texte fourni.\n"
    "Instructions impératives :\n"
    "1. Extrais uniquement les arguments et conclusions explicitement présents dans le texte. N'ajoute AUCUNE information ou interprétation externe.\n"
    "2. Si le texte mentionne des doutes, des limites ou des contre-arguments, tu DOIS les inclure dans le résumé.\n"
    "3. Ne généralise jamais au-delà de ce que l'auteur affirme.\n"
    "4. Commence ta réponse directement par le résumé, sans préambule."
)

# ---------------------------------------------------------------------------
# Helper functions
# ---------------------------------------------------------------------------

def fetch_articles(client: bigquery.Client) -> pd.DataFrame:
    """Return a batch of articles without summaries."""
    query = f"""
        SELECT url AS article_id, text
        FROM `{PROJECT_ID}.{DATASET}.{ARTICLE_TABLE}` AS a
        LEFT JOIN `{PROJECT_ID}.{DATASET}.{SUMMARY_TABLE}` AS s
        ON a.url = s.article_id
        WHERE s.article_id IS NULL AND a.text IS NOT NULL
        LIMIT {BATCH_SIZE}
    """
    logging.info("Fetching articles with query: %s", query)
    return client.query(query).to_dataframe()


def summarize(text: str) -> str:
    """Generate a cautious summary using the configured LLM."""
    if not OPENAI_API_KEY:
        logging.error("OPENAI_API_KEY is not set")
        return ""
    openai.api_key = OPENAI_API_KEY
    try:
        resp = openai.chat.completions.create(
            model=MODEL_NAME,
            messages=[{"role": "system", "content": SYSTEM_PROMPT}, {"role": "user", "content": text}],
            temperature=0.2,
        )
        content = resp.choices[0].message.content
        return content.strip() if content is not None else ""
    except Exception:
        logging.exception("LLM summarization failed")
        return ""


def store_summaries(client: bigquery.Client, rows: List[dict]) -> None:
    """Upload generated summaries to BigQuery."""
    if not rows:
        logging.info("No summaries to store")
        return
    df = pd.DataFrame(rows)
    table_ref = f"{client.project}.{DATASET}.{SUMMARY_TABLE}"
    job_config = bigquery.LoadJobConfig(write_disposition="WRITE_APPEND")
    logging.info("Uploading %d summaries to %s", len(df), table_ref)
    job = client.load_table_from_dataframe(df, table_ref, job_config=job_config)
    job.result()


async def run_article_summarizer_worker() -> None:
    """Main worker entry point."""
    if not PROJECT_ID or not DATASET:
        logging.error("Missing GCP configuration (GCP_PROJECT_ID, BQ_DATASET)")
        return
    client = create_bq_client(PROJECT_ID)
    articles = fetch_articles(client)
    if articles.empty:
        logging.info("No articles to summarize")
        return
    results: List[dict] = []
    for _, row in articles.iterrows():
        summary = summarize(row["text"])
        if not summary:
            continue
        results.append(
            {
                "article_id": row["article_id"],
                "summary_text": summary,
                "generated_by": MODEL_NAME,
                "generation_timestamp": datetime.now(timezone.utc),
                "is_human_validated": False,
            }
        )
    store_summaries(client, results)


if __name__ == "__main__":
    import asyncio

    asyncio.run(run_article_summarizer_worker())
